{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzGH3WHgksYg0bixGbyvxF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hideyuki-ogawa/autogen-hands-on/blob/main/autogen_pt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## マルチエージェントを動かすライブラリAutoGenを触ってみるハンズオン（2回目）\n",
        "\n",
        "- Microsoftが作っている\n",
        "- https://microsoft.github.io/autogen/\n",
        "- チュートリアルをちょっとだけ中身を変えて行う\n",
        "- ほかに有名なマルチエージェント系ライブラリ\n",
        "    - LangGraph: https://langchain-ai.github.io/langgraph/\n",
        "\n",
        "## 目次\n",
        "\n",
        "- 前回の復習（15分くらい）\n",
        "    - 基礎クラス\n",
        "    - コードをllmに書かせて実行\n",
        "- 新しい部分(45分くらい)\n",
        "    - Tool Use\n",
        "    - Conversation Patterns\n"
      ],
      "metadata": {
        "id": "G91WgEVmXqCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## まずは前回の復習\n",
        "\n",
        "- pip install\n",
        "- 基礎クラス\n",
        "- llmにコードを書かせて実行する\n",
        "\n",
        "今回もgpt-4o-miniを使って進めていきます。     \n",
        "別のllmも使えるのですが、また今度。     \n",
        "(解説を作る時間がなかった・・・)"
      ],
      "metadata": {
        "id": "ACEqo9yRYumn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFvXFSZAXmOk",
        "outputId": "a2acb4f9-5d14-44b8-c22a-38337f35768c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen\n",
            "  Downloading pyautogen-0.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting diskcache (from pyautogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from pyautogen)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting flaml (from pyautogen)\n",
            "  Downloading FLAML-2.3.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.26.4)\n",
            "Collecting openai>=1.3 (from pyautogen)\n",
            "  Downloading openai-1.50.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen) (24.1)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.9.2)\n",
            "Collecting python-dotenv (from pyautogen)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.4.0)\n",
            "Collecting tiktoken (from pyautogen)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.3->pyautogen)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.23.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen) (2024.9.11)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.3.2)\n",
            "Downloading pyautogen-0.3.0-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.2/345.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.50.2-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.3.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jiter, h11, flaml, diskcache, tiktoken, httpcore, docker, httpx, openai, pyautogen\n",
            "Successfully installed diskcache-5.6.3 docker-7.1.0 flaml-2.3.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.50.2 pyautogen-0.3.0 python-dotenv-1.0.1 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyautogen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import ConversableAgent\n",
        "from google.colab import userdata #コラボでAPI_KEYを扱う方法"
      ],
      "metadata": {
        "id": "wrjNWFJIY_7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8370a710-456e-42d0-a191-b8bc1c7716d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# エージェントの設定を作る\n",
        "\n",
        "model_name = 'gpt-4o-mini'\n",
        "api_key = userdata.get('gpt_api_key') # ここは自分のキー名を入れてください。\n",
        "llm_config = {\n",
        "    'config_list': [{\n",
        "        'model': model_name,\n",
        "        'api_key': api_key\n",
        "    }]\n",
        "}"
      ],
      "metadata": {
        "id": "0Fz6HMt0ZRin"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 一度だけAgentと話す\n",
        "\n",
        "agent = ConversableAgent(\n",
        "    name='greet_agent',\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode='NEVER',\n",
        "    system_message='You are a greeting agent.',\n",
        "    function_map=None\n",
        ")\n",
        "rep = agent.generate_reply(messages=[{'role': 'user', 'content': 'おはようございます。'}])\n",
        "print(rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGucgGOFZ8k6",
        "outputId": "6a33745a-ebf3-427b-ec88-302b171c2355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-27 21:37:13] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "おはようございます！今日はどんな一日になりそうですか？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# エージェント同士対話させる\n",
        "# 今回はmax_turns=3を渡し、対話回数の上限を３回までに制限\n",
        "\n",
        "llm_config1 = {\n",
        "    'config_list': [{\n",
        "        'model': model_name,\n",
        "        'api_key': api_key,\n",
        "        'temperature': 0\n",
        "    }]\n",
        "}\n",
        "llm_config2 = {\n",
        "    'config_list': [{\n",
        "        'model': model_name,\n",
        "        'api_key': api_key,\n",
        "        'temperature': 1\n",
        "    }]\n",
        "}\n",
        "\n",
        "a1 = ConversableAgent(\n",
        "    name='a1',\n",
        "    llm_config=llm_config1,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode='NEVER',\n",
        "    system_message='あなたはお笑いコンビの突っ込み担当です。相方が面白くなるように上手く会話してください。',\n",
        ")\n",
        "\n",
        "a2 = ConversableAgent(\n",
        "    name='a2',\n",
        "    llm_config=llm_config2,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode='NEVER',\n",
        "    system_message='あなたはお笑いコンビのボケ担当です。提供された話題について面白いことを言って盛り上げてください。'\n",
        ")\n",
        "\n",
        "result = a1.initiate_chat(\n",
        "    a2,\n",
        "    message='最近選挙が多いですねぇ',\n",
        "    max_turns=3\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oT3k-fsafdW",
        "outputId": "2e398644-4560-4c9c-cbb8-adc7dfbd3fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-27 21:42:19] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-27 21:42:20] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a1 (to a2):\n",
            "\n",
            "最近選挙が多いですねぇ\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "a2 (to a1):\n",
            "\n",
            "選挙が多いってことは、立候補者も多いってことですよね。もう、立候補者の名刺交換会やってほしいわ！「いえいえ、私も政治家ですが、名刺は渡しません。票をください！」みたいな！政策より名刺のデザインが勝負になってきたら面白いね！どこかの候補者が「私の名刺、金箔入りです！」とか言ってたら、やっぱり投票したくなっちゃうよ！\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "a1 (to a2):\n",
            "\n",
            "それ、確かに面白い！でも、金箔入りの名刺を持ってる候補者が「私の政策は金運アップです！」って言ったら、もうそれだけで投票しちゃうかも！でも、実際に金運アップしたら、他の候補者が「私の名刺はプラチナ入りです！」って言い出すかもしれないね。名刺バトルが始まったら、選挙じゃなくて名刺交換会になっちゃうよ！\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "a2 (to a1):\n",
            "\n",
            "それ、めっちゃ面白い！名刺交換会が選挙を制覇したら、逆に「名刺大臣」とかが誕生しちゃうよ！その大臣が「国民の皆さん、名刺はこうやって振りかざすと効果倍増です！」とか教えてくれたら、みんな名刺を高く掲げて歩く、名刺信者の街になっちゃう！もう街中が名刺業者の看板だらけになって、選挙カーの代わりに名刺入れカーが走ってるって想像したら、ちょっと面白い！\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "a1 (to a2):\n",
            "\n",
            "それ、最高だね！名刺入れカーが「皆さん、名刺をお持ちですか？今なら特別に名刺を10枚お配りします！」って走り回ってたら、もう選挙どころじゃないよ！みんな名刺を交換するために行列作って、名刺のデザインコンテストとか始まったら、もう政治の話なんてどこへやら！「私の名刺、実はQRコード付きなんです！」って言ったら、若者たちが一斉にスマホをかざして、名刺の中身をチェックし始めるとか、未来の選挙は名刺で決まる時代だね！\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "a2 (to a1):\n",
            "\n",
            "ほんとにそうなっちゃうね！未来の選挙は「名刺バトルロイヤル」で、候補者たちが名刺の裏に隠された特技を披露するみたいな！「私の名刺、実は折りたたんだらカラクリ仕掛けで出てくるんです！」とか「私の名刺、開いたらミニスピーカーが出てきて、政策を大音量で流します！」とかね！名刺のデザインがどんどん派手になって、「私の名刺にはLEDで光るギミックがあります！」とか言われたら、もう名刺が選挙の主役だよ！政府が「名刺は三枚まで持ってこい」ってルール作ったら、みんな必死にデザイン考え始める！最終的には名刺が国の通貨になったりしてね、「今日は新しい名刺作るために働きます」って！\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-qFgIMEb0Gb",
        "outputId": "6c5575fa-ea4f-4ea9-b025-b4f7cf72ee2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': '最近選挙が多いですねぇ', 'role': 'assistant', 'name': 'a1'},\n",
              " {'content': '選挙が多いってことは、立候補者も多いってことですよね。もう、立候補者の名刺交換会やってほしいわ！「いえいえ、私も政治家ですが、名刺は渡しません。票をください！」みたいな！政策より名刺のデザインが勝負になってきたら面白いね！どこかの候補者が「私の名刺、金箔入りです！」とか言ってたら、やっぱり投票したくなっちゃうよ！',\n",
              "  'role': 'user',\n",
              "  'name': 'a2'},\n",
              " {'content': 'それ、確かに面白い！でも、金箔入りの名刺を持ってる候補者が「私の政策は金運アップです！」って言ったら、もうそれだけで投票しちゃうかも！でも、実際に金運アップしたら、他の候補者が「私の名刺はプラチナ入りです！」って言い出すかもしれないね。名刺バトルが始まったら、選挙じゃなくて名刺交換会になっちゃうよ！',\n",
              "  'role': 'assistant',\n",
              "  'name': 'a1'},\n",
              " {'content': 'それ、めっちゃ面白い！名刺交換会が選挙を制覇したら、逆に「名刺大臣」とかが誕生しちゃうよ！その大臣が「国民の皆さん、名刺はこうやって振りかざすと効果倍増です！」とか教えてくれたら、みんな名刺を高く掲げて歩く、名刺信者の街になっちゃう！もう街中が名刺業者の看板だらけになって、選挙カーの代わりに名刺入れカーが走ってるって想像したら、ちょっと面白い！',\n",
              "  'role': 'user',\n",
              "  'name': 'a2'},\n",
              " {'content': 'それ、最高だね！名刺入れカーが「皆さん、名刺をお持ちですか？今なら特別に名刺を10枚お配りします！」って走り回ってたら、もう選挙どころじゃないよ！みんな名刺を交換するために行列作って、名刺のデザインコンテストとか始まったら、もう政治の話なんてどこへやら！「私の名刺、実はQRコード付きなんです！」って言ったら、若者たちが一斉にスマホをかざして、名刺の中身をチェックし始めるとか、未来の選挙は名刺で決まる時代だね！',\n",
              "  'role': 'assistant',\n",
              "  'name': 'a1'},\n",
              " {'content': 'ほんとにそうなっちゃうね！未来の選挙は「名刺バトルロイヤル」で、候補者たちが名刺の裏に隠された特技を披露するみたいな！「私の名刺、実は折りたたんだらカラクリ仕掛けで出てくるんです！」とか「私の名刺、開いたらミニスピーカーが出てきて、政策を大音量で流します！」とかね！名刺のデザインがどんどん派手になって、「私の名刺にはLEDで光るギミックがあります！」とか言われたら、もう名刺が選挙の主役だよ！政府が「名刺は三枚まで持ってこい」ってルール作ったら、みんな必死にデザイン考え始める！最終的には名刺が国の通貨になったりしてね、「今日は新しい名刺作るために働きます」って！',\n",
              "  'role': 'user',\n",
              "  'name': 'a2'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiUBlz7icNpy",
        "outputId": "600d9272-de18-48bc-fac9-29edf8820d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'usage_including_cached_inference': {'total_cost': 0.0007202999999999999,\n",
              "  'gpt-4o-mini-2024-07-18': {'cost': 0.0007202999999999999,\n",
              "   'prompt_tokens': 1654,\n",
              "   'completion_tokens': 787,\n",
              "   'total_tokens': 2441}},\n",
              " 'usage_excluding_cached_inference': {'total_cost': 0.0007202999999999999,\n",
              "  'gpt-4o-mini-2024-07-18': {'cost': 0.0007202999999999999,\n",
              "   'prompt_tokens': 1654,\n",
              "   'completion_tokens': 787,\n",
              "   'total_tokens': 2441}}}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## コードをllmに書かせて実行する"
      ],
      "metadata": {
        "id": "5I9Ho5kLclcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "from autogen import ConversableAgent\n",
        "from autogen.coding import LocalCommandLineCodeExecutor\n",
        "import datetime"
      ],
      "metadata": {
        "id": "r3Pc4kHncUjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_writer_system_message = \"\"\"You are a helpful AI assistant.\n",
        "Solve tasks using your coding and language skills.\n",
        "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
        "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
        "2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
        "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
        "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
        "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
        "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
        "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
        "Reply 'TERMINATE' in the end when everything is done.\n",
        "\"\"\"\n",
        "\n",
        "llm_config1 = {\n",
        "    'config_list': [{\n",
        "        'model': model_name,\n",
        "        'api_key': api_key,\n",
        "        'temperature': 0\n",
        "    }]\n",
        "}\n",
        "\n",
        "executor = LocalCommandLineCodeExecutor(\n",
        "    timeout=10,\n",
        "    work_dir='/content'\n",
        ")\n",
        "\n",
        "code_executor_agent = ConversableAgent(\n",
        "    name='code_executor',\n",
        "    llm_config=False,\n",
        "    code_execution_config={\n",
        "        'executor': executor},\n",
        "    human_input_mode='ALWAYS'\n",
        ")\n",
        "\n",
        "code_writer_agent = ConversableAgent(\n",
        "    name='code_writer',\n",
        "    llm_config=llm_config1,\n",
        "    system_message=code_writer_system_message,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode='NEVER'\n",
        ")\n",
        "\n",
        "today = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "chat_result = code_executor_agent.initiate_chat(\n",
        "    code_writer_agent,\n",
        "    message=f'今日は{today}です。MSFT と META の株価の年始からの変化率を算出してください。そしてそのグラフを \"stock-gains.png\" という名前で保存してください。'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLwwSk9XcwXz",
        "outputId": "9bf384f0-6df9-448e-ca8b-23d9a2f9e9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-27 21:54:04] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "code_executor (to code_writer):\n",
            "\n",
            "今日は2024-09-27です。MSFT と META の株価の年始からの変化率を算出してください。そしてそのグラフを \"stock-gains.png\" という名前で保存してください。\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer (to code_executor):\n",
            "\n",
            "まず、MSFT（Microsoft）とMETA（Meta Platforms）の株価データを取得し、年始からの変化率を計算します。その後、変化率をグラフにプロットして \"stock-gains.png\" という名前で保存します。\n",
            "\n",
            "以下の手順で進めます：\n",
            "\n",
            "1. Yahoo Finance APIを使用してMSFTとMETAの株価データを取得します。\n",
            "2. 年始の株価と現在の株価を比較して変化率を計算します。\n",
            "3. 変化率をグラフにプロットし、画像ファイルとして保存します。\n",
            "\n",
            "次のPythonコードを実行してください。\n",
            "\n",
            "```python\n",
            "# filename: stock_analysis.py\n",
            "import yfinance as yf\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# 株式シンボル\n",
            "symbols = ['MSFT', 'META']\n",
            "\n",
            "# 年始の日付\n",
            "start_date = '2024-01-01'\n",
            "end_date = '2024-09-27'\n",
            "\n",
            "# データを取得\n",
            "data = {symbol: yf.download(symbol, start=start_date, end=end_date)['Close'] for symbol in symbols}\n",
            "\n",
            "# 年始の株価と現在の株価を取得\n",
            "start_prices = {symbol: data[symbol].iloc[0] for symbol in symbols}\n",
            "current_prices = {symbol: data[symbol].iloc[-1] for symbol in symbols}\n",
            "\n",
            "# 変化率を計算\n",
            "change_rates = {symbol: (current_prices[symbol] - start_prices[symbol]) / start_prices[symbol] * 100 for symbol in symbols}\n",
            "\n",
            "# グラフを作成\n",
            "plt.bar(change_rates.keys(), change_rates.values(), color=['blue', 'green'])\n",
            "plt.title('Stock Price Change Rate from Jan 1, 2024 to Sep 27, 2024')\n",
            "plt.ylabel('Change Rate (%)')\n",
            "plt.savefig('stock-gains.png')\n",
            "plt.close()\n",
            "\n",
            "# 結果を表示\n",
            "print(change_rates)\n",
            "```\n",
            "\n",
            "このコードを実行して、MSFTとMETAの株価の年始からの変化率を計算し、グラフを保存してください。実行結果を教えてください。\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as code_executor. Provide feedback to code_writer. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\n",
            "code_executor (to code_writer):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: \n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "{'MSFT': 16.296816468614132, 'META': 63.97817229595485}\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer (to code_executor):\n",
            "\n",
            "MSFTの株価は年始から約16.30%上昇し、METAの株価は約63.98%上昇しました。グラフは \"stock-gains.png\" として保存されました。\n",
            "\n",
            "これでタスクは完了です。TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as code_executor. Provide feedback to code_writer. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ５分、自分で触ってみましょう\n",
        "\n",
        "\n",
        "# では、新しい内容をスタート\n",
        "\n",
        "- Tool Use  <===\n",
        "- Conversation Patterns\n",
        "\n",
        "## Tool Use\n",
        "\n",
        "- Function Calling 的な奴です\n",
        "- https://microsoft.github.io/autogen/docs/tutorial/tool-use"
      ],
      "metadata": {
        "id": "4xOZEZ09e2tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import register_function"
      ],
      "metadata": {
        "id": "gI3FPK3diKsy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plus_one(a: int) -> int:\n",
        "    '''整数に1を足す関数'''\n",
        "    if type(a) != int:\n",
        "        raise ValueError('input must be an integer or float.')\n",
        "    else:\n",
        "        return a + 1\n",
        "\n",
        "llm_config = {\n",
        "    'config_list': [{\n",
        "        'model': model_name,\n",
        "        'api_key': api_key\n",
        "    }]\n",
        "}\n",
        "\n",
        "assistant = ConversableAgent(\n",
        "    'assistant',\n",
        "    llm_config=llm_config,\n",
        "    system_message='あなたは優秀なアシスタントです'\n",
        "    '私たちの計算を手伝ってください'\n",
        "    '仕事が終わったら \"TERMINATE\" と返してください'\n",
        ")\n",
        "user_proxy = ConversableAgent(\n",
        "    'user_proxy',\n",
        "    llm_config=False,\n",
        "    human_input_mode='NEVER',\n",
        "    max_consecutive_auto_reply=5,\n",
        "    is_termination_msg=lambda msg: msg['content'] is not None and \"TERMINATE\" in msg['content']\n",
        ")\n",
        "\n",
        "# assistant.register_for_llm(name='plus_one', description='整数に1を足す関数')(plus_one)\n",
        "# user_proxy.register_for_execution(name='plus_one')(plus_one)\n",
        "register_function(\n",
        "    plus_one,\n",
        "    caller=assistant,\n",
        "    executor=user_proxy,\n",
        "    name='plus_one',\n",
        "    description='整数に1を足す関数'\n",
        ")\n",
        "\n",
        "chat_result = user_proxy.initiate_chat(\n",
        "    assistant,\n",
        "    message='39に4を足してください。'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGb-NpVkc8bn",
        "outputId": "bdafdfc9-ecde-40d4-e881-d0b4981aba75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:11:47] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:11:47] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to assistant):\n",
            "\n",
            "39に4を足してください。\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "assistant (to user_proxy):\n",
            "\n",
            "***** Suggested tool call (call_ZBsD7HZtdQQJsp381G94IhMM): plus_one *****\n",
            "Arguments: \n",
            "{\"a\": 39}\n",
            "*************************************************************************\n",
            "***** Suggested tool call (call_05Y57gWUFBSYnnO5ryyVfzPu): plus_one *****\n",
            "Arguments: \n",
            "{\"a\": 40}\n",
            "*************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION plus_one...\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION plus_one...\n",
            "user_proxy (to assistant):\n",
            "\n",
            "user_proxy (to assistant):\n",
            "\n",
            "***** Response from calling tool (call_ZBsD7HZtdQQJsp381G94IhMM) *****\n",
            "40\n",
            "**********************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "user_proxy (to assistant):\n",
            "\n",
            "***** Response from calling tool (call_05Y57gWUFBSYnnO5ryyVfzPu) *****\n",
            "41\n",
            "**********************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "assistant (to user_proxy):\n",
            "\n",
            "39に4を足すと、43になります。仕事が終わったら \"TERMINATE\" と返してください。\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assistant.llm_config['tools']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa90WTwUjBhM",
        "outputId": "980b845e-48ad-435a-c258-0592ef11be51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'function': {'description': '整数に1を足す関数',\n",
              "   'name': 'plus_one',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'a': {'type': 'integer', 'description': 'a'}},\n",
              "    'required': ['a']}}}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result.cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35-mp7OveRLy",
        "outputId": "6f79a505-ee3a-4ac3-cea3-ff65b85f20d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'usage_including_cached_inference': {'total_cost': 8.039999999999999e-05,\n",
              "  'gpt-4o-mini-2024-07-18': {'cost': 8.039999999999999e-05,\n",
              "   'prompt_tokens': 252,\n",
              "   'completion_tokens': 71,\n",
              "   'total_tokens': 323}},\n",
              " 'usage_excluding_cached_inference': {'total_cost': 8.039999999999999e-05,\n",
              "  'gpt-4o-mini-2024-07-18': {'cost': 8.039999999999999e-05,\n",
              "   'prompt_tokens': 252,\n",
              "   'completion_tokens': 71,\n",
              "   'total_tokens': 323}}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 対話パターン\n",
        "\n",
        "- ２つのエージェントの対話\n",
        "    - これは今まで見てきたので飛ばします\n",
        "- 連続対話\n",
        "- グループ対話\n",
        "- ネスト対話\n",
        "\n",
        "\n",
        "まずは連続対話から\n",
        "\n",
        "### 連続対話\n",
        "\n",
        "２つのエージェント間の対話が連続する。キャリーオーバーの機能により、対話がつながれる。\n",
        "\n",
        "- ここの画像で確認: https://microsoft.github.io/autogen/docs/tutorial/conversation-patterns#sequential-chats\n",
        "\n",
        "Aさんが、B, C, D, Eさんと次々と対話。対話内容はキャリーオーバーされるため、その内容を反映して対話が続く（よくあるチャットアプリみたいな感じ）"
      ],
      "metadata": {
        "id": "rTRZ9Us1ix1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'gpt-4o'\n",
        "llm_config = {\n",
        "    'config_list': [{\n",
        "        'model': model_name,\n",
        "        'api_key': api_key,\n",
        "        'temperature': 0\n",
        "    }]\n",
        "}\n",
        "\n",
        "number_agent = ConversableAgent(\n",
        "    name=\"Number_Agent\",\n",
        "    system_message=\"You return me the numbers I give you, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Adder Agent adds 1 to each number it receives.\n",
        "adder_agent = ConversableAgent(\n",
        "    name=\"Adder_Agent\",\n",
        "    system_message=\"You add 1 to each number I give you and return me the new numbers, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Multiplier Agent multiplies each number it receives by 2.\n",
        "multiplier_agent = ConversableAgent(\n",
        "    name=\"Multiplier_Agent\",\n",
        "    system_message=\"You multiply each number I give you by 2 and return me the new numbers, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Subtracter Agent subtracts 1 from each number it receives.\n",
        "subtracter_agent = ConversableAgent(\n",
        "    name=\"Subtracter_Agent\",\n",
        "    system_message=\"You subtract 1 from each number I give you and return me the new numbers, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Divider Agent divides each number it receives by 2.\n",
        "divider_agent = ConversableAgent(\n",
        "    name=\"Divider_Agent\",\n",
        "    system_message=\"You divide each number I give you by 2 and return me the new numbers, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "chat_results = number_agent.initiate_chats(\n",
        "    [\n",
        "        {\n",
        "            \"recipient\": adder_agent,\n",
        "            \"message\": \"14\",\n",
        "            \"max_turns\": 2,\n",
        "            \"summary_method\": \"last_msg\",\n",
        "        },\n",
        "        {\n",
        "            \"recipient\": multiplier_agent,\n",
        "            \"message\": \"These are my numbers\",\n",
        "            \"max_turns\": 2,\n",
        "            \"summary_method\": \"last_msg\",\n",
        "        },\n",
        "        {\n",
        "            \"recipient\": subtracter_agent,\n",
        "            \"message\": \"These are my numbers\",\n",
        "            \"max_turns\": 2,\n",
        "            \"summary_method\": \"last_msg\",\n",
        "        },\n",
        "        {\n",
        "            \"recipient\": divider_agent,\n",
        "            \"message\": \"These are my numbers\",\n",
        "            \"max_turns\": 2,\n",
        "            \"summary_method\": \"last_msg\",\n",
        "        },\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3s2IRenc9Hw",
        "outputId": "f510d41f-0da0-44d1-f68e-f8382acb7e57"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:25:53] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:25:53] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:25:54] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:25:54] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:25:54] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Number_Agent (to Adder_Agent):\n",
            "\n",
            "14\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Adder_Agent (to Number_Agent):\n",
            "\n",
            "15\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Number_Agent (to Adder_Agent):\n",
            "\n",
            "15\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Adder_Agent (to Number_Agent):\n",
            "\n",
            "16\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Number_Agent (to Multiplier_Agent):\n",
            "\n",
            "These are my numbers\n",
            "Context: \n",
            "16\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Multiplier_Agent (to Number_Agent):\n",
            "\n",
            "32\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Number_Agent (to Multiplier_Agent):\n",
            "\n",
            "32\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Multiplier_Agent (to Number_Agent):\n",
            "\n",
            "64\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Number_Agent (to Subtracter_Agent):\n",
            "\n",
            "These are my numbers\n",
            "Context: \n",
            "16\n",
            "64\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Subtracter_Agent (to Number_Agent):\n",
            "\n",
            "15\n",
            "63\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Number_Agent (to Subtracter_Agent):\n",
            "\n",
            "14\n",
            "62\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Subtracter_Agent (to Number_Agent):\n",
            "\n",
            "13\n",
            "61\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Number_Agent (to Divider_Agent):\n",
            "\n",
            "These are my numbers\n",
            "Context: \n",
            "16\n",
            "64\n",
            "13\n",
            "61\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Divider_Agent (to Number_Agent):\n",
            "\n",
            "8\n",
            "32\n",
            "6.5\n",
            "30.5\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Number_Agent (to Divider_Agent):\n",
            "\n",
            "8\n",
            "32\n",
            "6.5\n",
            "30.5\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Divider_Agent (to Number_Agent):\n",
            "\n",
            "4\n",
            "16\n",
            "3.25\n",
            "15.25\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for num, chat_result in enumerate(chat_results):\n",
        "    print(f'{num}: {chat_result.summary}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta5IMGZhmFZ_",
        "outputId": "1ad40838-6e77-433d-eccd-1fa9648b2a3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 16\n",
            "1: 64\n",
            "2: 13\n",
            "61\n",
            "3: 4\n",
            "16\n",
            "3.25\n",
            "15.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### グループチャット\n",
        "\n",
        "- https://microsoft.github.io/autogen/docs/tutorial/conversation-patterns#group-chat\n",
        "\n",
        "2つのエージェント以上との対話パターン。複数のエージェントのコラボレーションが必要なタスクに役立つ。\n",
        "\n",
        "- 登場人物\n",
        "    - グループチャットマネージャー\n",
        "    - Agent A - D\n",
        "\n",
        "- グループチャットマネージャーがタスクをどれかのエージェントに振る\n",
        "- エージェントから答えが返される\n",
        "- グループチャットマネージャーが全員にそれを伝える\n",
        "\n",
        "というのがループする。\n",
        "\n",
        "グループチャットマネージャーが話者を選ぶ方法がいくつかある。\n",
        "\n",
        "- round_robin: 指定されたエージェントの順番に従い、ラウンドロビン方式でエージェントを選択します\n",
        "- random: ランダムに選択\n",
        "- manual: 人間の入力を求めてエージェントを選択します。\n",
        "- auto: デフォルトの戦略で、Group Chat ManagerのLLMを使用してエージェントを選択します。"
      ],
      "metadata": {
        "id": "NKQKngzQnTzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# グループチャットマネージャーが次のエージェントを選ぶのを助けるために、エージェントの概要を付ける\n",
        "# autoでやる場合必要。descriptionがない場合、グループチャットマネージャーはエージェントのシステムメッセージを\n",
        "# 参考にエージェントを選ぶが、ベストチョイスではない。\n",
        "# descriptionは ConversableAgentでも設定できる・\n",
        "\n",
        "adder_agent.description = \"Add 1 to each input number.\"\n",
        "multiplier_agent.description = \"Multiply each input number by 2.\"\n",
        "subtracter_agent.description = \"Subtract 1 from each input number.\"\n",
        "divider_agent.description = \"Divide each input number by 2.\"\n",
        "number_agent.description = \"Return the numbers given.\""
      ],
      "metadata": {
        "id": "1LioB_flm_c1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import GroupChat, GroupChatManager\n",
        "\n",
        "model_name = 'gpt-4o-mini'\n",
        "llm_config = {\n",
        "    'config_list': [{\n",
        "        'model': model_name,\n",
        "        'api_key': api_key,\n",
        "        'temperature': 0\n",
        "    }]\n",
        "}\n",
        "\n",
        "\n",
        "number_agent = ConversableAgent(\n",
        "    name=\"Number_Agent\",\n",
        "    system_message=\"You return me the numbers I give you, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Adder Agent adds 1 to each number it receives.\n",
        "adder_agent = ConversableAgent(\n",
        "    name=\"Adder_Agent\",\n",
        "    system_message=\"You add 1 to each number I give you and return me the new numbers, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Multiplier Agent multiplies each number it receives by 2.\n",
        "multiplier_agent = ConversableAgent(\n",
        "    name=\"Multiplier_Agent\",\n",
        "    system_message=\"You multiply each number I give you by 2 and return me the new numbers, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Subtracter Agent subtracts 1 from each number it receives.\n",
        "subtracter_agent = ConversableAgent(\n",
        "    name=\"Subtracter_Agent\",\n",
        "    system_message=\"You subtract 1 from each number I give you and return me the new numbers, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Divider Agent divides each number it receives by 2.\n",
        "divider_agent = ConversableAgent(\n",
        "    name=\"Divider_Agent\",\n",
        "    system_message=\"You divide each number I give you by 2 and return me the new numbers, one number each line.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "groupchat = GroupChat(\n",
        "    agents=[number_agent, adder_agent, multiplier_agent, subtracter_agent, divider_agent],\n",
        "    messages=[],\n",
        "    max_round=6\n",
        ")\n",
        "group_chat_manager = GroupChatManager(\n",
        "    groupchat=groupchat,\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "\n",
        "chat_result = number_agent.initiate_chat(\n",
        "    group_chat_manager,\n",
        "    message='my number is 3, I want turn it into 13',\n",
        "    summary_method='reflection_with_llm'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97gJo_4Wp4Ff",
        "outputId": "faef310d-cbe4-42d5-b197-430dc304e3e7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:31:01] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:31:01] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:31:02] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:31:02] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:31:02] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:31:02] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number_Agent (to chat_manager):\n",
            "\n",
            "my number is 3, I want turn it into 13\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:31:02] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Adder_Agent\n",
            "\n",
            "Adder_Agent (to chat_manager):\n",
            "\n",
            "4  \n",
            "5  \n",
            "6  \n",
            "7  \n",
            "8  \n",
            "9  \n",
            "10  \n",
            "11  \n",
            "12  \n",
            "13  \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:31:02] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Multiplier_Agent\n",
            "\n",
            "Multiplier_Agent (to chat_manager):\n",
            "\n",
            "6  \n",
            "8  \n",
            "10  \n",
            "12  \n",
            "14  \n",
            "16  \n",
            "18  \n",
            "20  \n",
            "22  \n",
            "24  \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:31:10] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Subtracter_Agent\n",
            "\n",
            "Subtracter_Agent (to chat_manager):\n",
            "\n",
            "2  \n",
            "3  \n",
            "4  \n",
            "5  \n",
            "6  \n",
            "7  \n",
            "8  \n",
            "9  \n",
            "10  \n",
            "11  \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:31:10] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Divider_Agent\n",
            "\n",
            "Divider_Agent (to chat_manager):\n",
            "\n",
            "1.5  \n",
            "2  \n",
            "3  \n",
            "3.5  \n",
            "4  \n",
            "4.5  \n",
            "5  \n",
            "5.5  \n",
            "6  \n",
            "6.5  \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:31:10] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Number_Agent\n",
            "\n",
            "Number_Agent (to chat_manager):\n",
            "\n",
            "3  \n",
            "4  \n",
            "5  \n",
            "6  \n",
            "7  \n",
            "8  \n",
            "9  \n",
            "10  \n",
            "11  \n",
            "12  \n",
            "13  \n",
            "6  \n",
            "8  \n",
            "10  \n",
            "12  \n",
            "14  \n",
            "16  \n",
            "18  \n",
            "20  \n",
            "22  \n",
            "24  \n",
            "2  \n",
            "3  \n",
            "4  \n",
            "5  \n",
            "6  \n",
            "7  \n",
            "8  \n",
            "9  \n",
            "10  \n",
            "11  \n",
            "1.5  \n",
            "2  \n",
            "3  \n",
            "3.5  \n",
            "4  \n",
            "4.5  \n",
            "5  \n",
            "5.5  \n",
            "6  \n",
            "6.5  \n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_result.summary)"
      ],
      "metadata": {
        "id": "cCedaVAZqbyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fabe5f4-7f8e-45e0-a086-934e2fa09cb2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The conversation involves a series of mathematical operations to transform the number 3 into 13. The Adder_Agent provides a sequence of numbers leading up to 13 by adding increments, while the Multiplier_Agent lists multiples of 2 starting from 6. The Subtracter_Agent offers a range of numbers obtained by subtracting from 3, and the Divider_Agent presents results from dividing 3 by various factors. Each agent contributes different methods to reach or approach the target number of 13.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 上の状態だと、グループチャットマネージャーにしか、自己紹介が役立たない\n",
        "# GroupChat の send_introductionsに Trueを渡すと、参加するエージェントに自己紹介が伝わる。\n",
        "# グループチャットマネージャーが各エージェントのdescriptionを会話の最初に送る\n",
        "\n",
        "group_chat_with_introductions = GroupChat(\n",
        "    agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n",
        "    messages=[],\n",
        "    max_round=6,\n",
        "    send_introductions=True,\n",
        ")\n",
        "\n",
        "group_chat_manager_with_intros = GroupChatManager(\n",
        "    groupchat=group_chat_with_introductions,\n",
        "    llm_config=llm_config\n",
        ")\n",
        "\n",
        "# Start a sequence of two-agent chats between the number agent and\n",
        "# the group chat manager.\n",
        "chat_result = number_agent.initiate_chats(\n",
        "    [\n",
        "        {\n",
        "            \"recipient\": group_chat_manager_with_intros,\n",
        "            \"message\": \"My number is 3, I want to turn it into 13.\",\n",
        "        },\n",
        "        {\n",
        "            \"recipient\": group_chat_manager_with_intros,\n",
        "            \"message\": \"Turn this number to 32.\",\n",
        "        },\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmswAc-Ghr_6",
        "outputId": "d4d10957-5443-4023-8425-c79e9e74a146"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 07:33:30] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Number_Agent (to chat_manager):\n",
            "\n",
            "My number is 3, I want to turn it into 13.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:30] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogen/agentchat/chat.py:53: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n",
            "  warnings.warn(\n",
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Adder_Agent\n",
            "\n",
            "Adder_Agent (to chat_manager):\n",
            "\n",
            "3  \n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:31] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Adder_Agent\n",
            "\n",
            "Adder_Agent (to chat_manager):\n",
            "\n",
            "4\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:32] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Adder_Agent\n",
            "\n",
            "Adder_Agent (to chat_manager):\n",
            "\n",
            "5  \n",
            "6  \n",
            "7  \n",
            "8  \n",
            "9  \n",
            "10  \n",
            "11  \n",
            "12  \n",
            "13  \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:33] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Multiplier_Agent\n",
            "\n",
            "Multiplier_Agent (to chat_manager):\n",
            "\n",
            "6  \n",
            "8  \n",
            "10  \n",
            "12  \n",
            "14  \n",
            "16  \n",
            "18  \n",
            "20  \n",
            "22  \n",
            "24  \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:34] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Subtracter_Agent\n",
            "\n",
            "Subtracter_Agent (to chat_manager):\n",
            "\n",
            "2  \n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Number_Agent (to chat_manager):\n",
            "\n",
            "Turn this number to 32.\n",
            "Context: \n",
            "2  \n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:35] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Adder_Agent\n",
            "\n",
            "Adder_Agent (to chat_manager):\n",
            "\n",
            "3\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:36] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Multiplier_Agent\n",
            "\n",
            "Multiplier_Agent (to chat_manager):\n",
            "\n",
            "4\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:37] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Subtracter_Agent\n",
            "\n",
            "Subtracter_Agent (to chat_manager):\n",
            "\n",
            "1\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:38] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Divider_Agent\n",
            "\n",
            "Divider_Agent (to chat_manager):\n",
            "\n",
            "1\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 07:33:38] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Number_Agent\n",
            "\n",
            "Number_Agent (to chat_manager):\n",
            "\n",
            "4  \n",
            "8  \n",
            "0  \n",
            "0.5  \n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nested Chats\n",
        "\n",
        "- 複数のエージェントや処理を組み合わせて、段階的に作業を進める\n",
        "- それにより、複雑な作業にも対応できる\n",
        "- 多分 [o1](https://openai.com/index/introducing-openai-o1-preview/) なんかもこういうことなんだろうと勝手に思っている。\n",
        "\n",
        "https://microsoft.github.io/autogen/docs/tutorial/conversation-patterns#nested-chats"
      ],
      "metadata": {
        "id": "wEtxj91ujQJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\n",
        "    'config_list': [{\n",
        "        'model': model_name,\n",
        "        'api_key': api_key,\n",
        "        'temperature': 0\n",
        "    }]\n",
        "}\n",
        "\n",
        "arithmetic_agent = ConversableAgent(\n",
        "    name='arithmetic_agent',\n",
        "    llm_config=False,\n",
        "    human_input_mode='ALWAYS',\n",
        "    code_execution_config={'use_docker': False, 'work_dir': '/content'}\n",
        ")\n",
        "\n",
        "code_writer_agent = ConversableAgent(\n",
        "    name='code_writer_agent',\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"You are a code writer. You write Python script in Markdown code blocks.\",\n",
        "    human_input_mode='NEVER',\n",
        ")\n",
        "\n",
        "poetry_agent = ConversableAgent(\n",
        "    name='poetry_agent',\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode='NEVER',\n",
        "    system_message='You are an AI poet.'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_c4_W6gjK3W",
        "outputId": "3c53eea8-50da-4a26-8b02-585e0e0e27b8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 08:06:21] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-28 08:06:21] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nested Chatを連続チャットをつかっ作る\n",
        "\n",
        "nested_chats = [\n",
        "    {\n",
        "    'recipient': group_chat_manager_with_intros,\n",
        "    'summary_method': 'reflection_with_llm',\n",
        "    'summary_prompt': 'Summarize the sequence of operations used to turn'\n",
        "    },\n",
        "    {\n",
        "        'recipient': code_writer_agent,\n",
        "        'message': 'Write a Python script to verify the arithmetic operations is correct.',\n",
        "        'summary_method': 'reflection_with_llm',\n",
        "    },\n",
        "    {\n",
        "        'recipient': poetry_agent,\n",
        "        'message': 'write a poem about it.',\n",
        "        'max_turns': 1,\n",
        "        'summary_method': 'last_msg'\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "bx03EzoOqosn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arithmetic_agent.register_nested_chats(\n",
        "    nested_chats,\n",
        "    trigger=lambda sender: sender not in [group_chat_manager_with_intros, code_writer_agent, poetry_agent],\n",
        ")"
      ],
      "metadata": {
        "id": "Dif5K9wWretL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = arithmetic_agent.generate_reply(\n",
        "    messages=[{'role': 'user', 'content': 'I have a number 3 and I want to turn it into 7.'}]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uei5UMxgr6m0",
        "outputId": "606d96bc-2ae4-4753-c7e9-436baaa9d1d0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replying as arithmetic_agent. Provide feedback to the sender. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "arithmetic_agent (to chat_manager):\n",
            "\n",
            "I have a number 3 and I want to turn it into 7.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 08:13:43] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Adder_Agent\n",
            "\n",
            "Adder_Agent (to chat_manager):\n",
            "\n",
            "4\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 08:13:44] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Adder_Agent\n",
            "\n",
            "Adder_Agent (to chat_manager):\n",
            "\n",
            "5\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 08:13:45] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Adder_Agent\n",
            "\n",
            "Adder_Agent (to chat_manager):\n",
            "\n",
            "6\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 08:13:45] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Adder_Agent\n",
            "\n",
            "Adder_Agent (to chat_manager):\n",
            "\n",
            "7\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-28 08:13:46] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: Number_Agent\n",
            "\n",
            "Number_Agent (to chat_manager):\n",
            "\n",
            "8\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "arithmetic_agent (to code_writer_agent):\n",
            "\n",
            "Write a Python script to verify the arithmetic operations is correct.\n",
            "Context: \n",
            "The conversation involves a series of additions starting from the number 3, with the goal of reaching 7. The correct addition to reach 7 from 3 is 4.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to arithmetic_agent):\n",
            "\n",
            "Here is a Python script that verifies if the arithmetic operation of adding a number to 3 results in 7:\n",
            "\n",
            "```python\n",
            "def verify_addition(start, addend, expected_result):\n",
            "    result = start + addend\n",
            "    return result == expected_result\n",
            "\n",
            "# Starting number\n",
            "start_number = 3\n",
            "# Number to add\n",
            "addend = 4\n",
            "# Expected result\n",
            "expected_result = 7\n",
            "\n",
            "# Verify the addition\n",
            "is_correct = verify_addition(start_number, addend, expected_result)\n",
            "\n",
            "if is_correct:\n",
            "    print(f\"The addition of {start_number} and {addend} is correct, resulting in {expected_result}.\")\n",
            "else:\n",
            "    print(f\"The addition of {start_number} and {addend} is incorrect.\")\n",
            "```\n",
            "\n",
            "This script defines a function to verify the addition and checks if adding 4 to 3 results in 7. It then prints whether the operation is correct or not.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as arithmetic_agent. Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n",
            "arithmetic_agent (to code_writer_agent):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: \n",
            "The addition of 3 and 4 is correct, resulting in 7.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to arithmetic_agent):\n",
            "\n",
            "Great! It looks like the script executed successfully and confirmed that the addition of 3 and 4 is indeed correct, resulting in 7. If you have any more arithmetic operations to verify or any other questions, feel free to ask!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as arithmetic_agent. Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "arithmetic_agent (to code_writer_agent):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to arithmetic_agent):\n",
            "\n",
            "It seems like you might not have a specific request at the moment. If you have any questions or need assistance with anything else, whether it's related to arithmetic operations, Python programming, or any other topic, just let me know!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as arithmetic_agent. Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: write poem about it.\n",
            "arithmetic_agent (to code_writer_agent):\n",
            "\n",
            "write poem about it.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "code_writer_agent (to arithmetic_agent):\n",
            "\n",
            "Here’s a poem inspired by the arithmetic operation of adding to reach a goal:\n",
            "\n",
            "---\n",
            "\n",
            "**In Numbers We Trust**\n",
            "\n",
            "In the realm of numbers, where logic does play,  \n",
            "A journey begins at the break of the day.  \n",
            "From three, we set forth, with a goal in our sight,  \n",
            "To reach the sweet seven, a number so bright.\n",
            "\n",
            "With a whisper of four, we add to our start,  \n",
            "A simple addition, yet it warms the heart.  \n",
            "Three plus four dances, a rhythm so true,  \n",
            "In the world of arithmetic, it’s me and you.\n",
            "\n",
            "Oh, the joy of the sum, as we count and we play,  \n",
            "Each digit a story, in its own special way.  \n",
            "From the depths of our minds, to the paper we write,  \n",
            "In numbers we trust, as we chase after light.\n",
            "\n",
            "So here’s to the math, and the paths that we take,  \n",
            "To find all the answers, for knowledge’s sake.  \n",
            "With each little sum, we grow and we learn,  \n",
            "In the dance of addition, our passions will burn.\n",
            "\n",
            "---\n",
            "\n",
            "I hope you enjoyed the poem! If you have any other requests or themes in mind, feel free to share!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as arithmetic_agent. Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "arithmetic_agent (to poetry_agent):\n",
            "\n",
            "write a poem about it.\n",
            "Context: \n",
            "The conversation involves a series of additions starting from the number 3, with the goal of reaching 7. The correct addition to reach 7 from 3 is 4.\n",
            "The conversation involved verifying the arithmetic operation of adding 4 to 3 to reach the result of 7. A Python script was provided to confirm the correctness of this addition, which was successful. Additionally, a poem was created to celebrate the beauty of arithmetic and the joy of learning through numbers.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "poetry_agent (to arithmetic_agent):\n",
            "\n",
            "In the realm where numbers dance and play,  \n",
            "A tale unfolds in a curious way.  \n",
            "From the humble start of three, so bright,  \n",
            "A journey begins, guided by light.  \n",
            "\n",
            "With whispers of addition, a path to explore,  \n",
            "What magic awaits when we open the door?  \n",
            "Four steps forward, a leap through the air,  \n",
            "To reach for the heavens, a number so rare.  \n",
            "\n",
            "Three plus four, a simple delight,  \n",
            "Unveils the treasure, a number in sight.  \n",
            "Seven emerges, a beacon of grace,  \n",
            "In the world of arithmetic, it finds its place.  \n",
            "\n",
            "Oh, the joy of learning, the thrill of the chase,  \n",
            "In every equation, a new kind of space.  \n",
            "With Python as scribe, we verify truth,  \n",
            "In the language of numbers, we find our youth.  \n",
            "\n",
            "So let us celebrate this wondrous art,  \n",
            "Where digits and symbols play their part.  \n",
            "For in every sum, a story is spun,  \n",
            "In the heart of arithmetic, we are all one.  \n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cb7FBXQysS1A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}